{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b1f2de",
   "metadata": {},
   "source": [
    "### 0. Imports and pre-process required files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e59c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements installation (for Jupyter)\n",
    "!{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org selenium\n",
    "!{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org tkinter\n",
    "!{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org pickle5\n",
    "!{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org pandas\n",
    "!{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org numpy\n",
    "!{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org wakepy\n",
    "!{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org investpy\n",
    "!{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org countrynames\n",
    "!{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org ccy\n",
    "!{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org pyodbc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c61a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements installation (for Windows)\n",
    "\n",
    "import subprocess\n",
    "\n",
    "subprocess.run(f'pip config set global.trusted-host \"pypi.org files.pythonhosted.org pypi.python.org\"', shell=True)\n",
    "\n",
    "dependencies = ['selenium', 'webdriver-manager', 'chromium-chromedriver',\n",
    "                'tkinter', 'pickle5', 'pandas', 'numpy', 'wakepy', 'investpy',\n",
    "                'countrynames', 'ccy', 'pyodbc', 'openpyxl']\n",
    "\n",
    "for dependency in dependencies:\n",
    "    # For bank's server (linux-based)\n",
    "    # command = f'{sys.executable} -m pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org {dependency}'\n",
    "    \n",
    "    # For localhost (windows)\n",
    "    command = f'pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org {dependency}'\n",
    "    \n",
    "    subprocess.run(command, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual PIA import (Hive) to pia_imported.csv (./input)\n",
    "%run -i ./system_modules/pia_prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0ba486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual BR.xlsx (./input) to BR_N.csv (./source_files)\n",
    "%run -i ./system_modules/br_prep.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fc4e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual SR (DSR, ESR, FFR) import from Hive to SR_N.csv (./source_files)\n",
    "from system_modules.sys_class import *\n",
    "try:\n",
    "    SR_cache = cache(name='SR', data=pd.read_csv('./source_files/SR_N.csv'))\n",
    "    SR_cache.path = './system_modules/SR.cache'\n",
    "    SR_cache.cached()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "%run -i ./system_modules/sr_prep.py\n",
    "\n",
    "os.remove(SR_cache.path)\n",
    "os.remove('./system_modules/SR.cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b6f95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual SR (ISR) import from Hive to ISR_N.csv (./source_files)\n",
    "from system_modules.sys_class import *\n",
    "try:\n",
    "    ISR_cache = cache(name='ISR', data=pd.read_csv('./source_files/ISR_N.csv'))\n",
    "    ISR_cache.path = './system_modules/ISR.cache'\n",
    "    ISR_cache.cached()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "%run -i ./system_modules/isr_prep.py\n",
    "\n",
    "os.remove(ISR_cache.path)\n",
    "os.remove('./system_modules/ISR.cache')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2232c92",
   "metadata": {},
   "source": [
    "### 1. Define and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81e2e68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imports and defines\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.getcwd()+'/system_modules/')\n",
    "\n",
    "from system_modules.imports import *\n",
    "from system_modules.sys_functions import *\n",
    "from system_modules.sys_class import *\n",
    "from system_modules.sys_security import *\n",
    "from system_modules.sys_investor import *\n",
    "\n",
    "try:\n",
    "    # Load input file and generate/read cache\n",
    "    TMP_PIA_DF_NAME, TMP_PIA_DF = df_finds(keyword='pia', requiredName=True)\n",
    "    NEW_PIA_DF = DataFrameFile(name = TMP_PIA_DF_NAME, dataframe = TMP_PIA_DF)\n",
    "\n",
    "    # Generate empty tables or read if exists\n",
    "    YEARLY_PIA_DF = DataFrameFile(name=f'YEARLY_PIA_DF_{datetime.today().year}',\n",
    "                                  dataframe=df_read(name=f'YEARLY_PIA_DF_{datetime.today().year}',\n",
    "                                                    clone=pd.DataFrame(columns=['msr_prd_id', 'end_ivstr_unq_id_tp', 'pvr_role_rspn', \n",
    "                                                                                'org_ip_id', 'RID', 'end_ivstr_nm',\n",
    "                                                                                'SECTOR', 'ISIC4_CLID','orig_ccy_cost_val',\n",
    "                                                                                'orig_ccy_mkt_val', 'scr_code', 'BOP_item',\n",
    "                                                                                'issuer_name', 'issuer_countryID',\n",
    "                                                                                'scr_currencyID', 'scr_termID', 'scr_instrument'\n",
    "                                                                                ])))\n",
    "    \n",
    "    INVESTOR_TABLE = DataFrameFile(name='INVESTOR_TABLE',\n",
    "                                  dataframe=df_read(name='INVESTOR_TABLE',\n",
    "                                                   clone=pd.DataFrame(columns=['RID','end_ivstr_unq_id_tp',\n",
    "                                                                               'end_ivstr_nm','pvr_role_rspn',\n",
    "                                                                               'org_ip_id', 'SECTOR','ISIC4_CLID'\n",
    "                                                                               ])))\n",
    "    \n",
    "    SECURITY_TABLE = DataFrameFile(name='SECURITY_TABLE',\n",
    "                                  dataframe=df_read(name='SECURITY_TABLE',\n",
    "                                                   clone=pd.DataFrame(columns=['scr_code', 'BOP_item', 'issuer_name',\n",
    "                                                                               'issuer_countryID', 'scr_currencyID',\n",
    "                                                                               'scr_termID', 'scr_instrument'])))\n",
    "    \n",
    "    NEW_PIA_CACHE = cache(name=TMP_PIA_DF_NAME)\n",
    "    \n",
    "except:\n",
    "    traceback_log()\n",
    "    print('Error occured')\n",
    "    \n",
    "else:\n",
    "    finished(f'start.ipynb (Imports and defines), file name: {TMP_PIA_DF_NAME}, total data rows to-be processed is {len(NEW_PIA_DF.dataframe)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55b76b5",
   "metadata": {},
   "source": [
    "### 2.1 End Investor Process\n",
    "- BR data mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7387d0da",
   "metadata": {},
   "source": [
    "##### 2.1.1 Normal Investor Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3704caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End Investor Process\n",
    "from system_modules.sys_investor import *\n",
    "\n",
    "try:\n",
    "    print(f\"start.ipynb (Investor Process): pre-process found row counts is {len(INVESTOR_TABLE.dataframe)} {datetime.now()}\")\n",
    "    INVESTOR_TABLE = investor_validation(NEW_PIA_DF, INVESTOR_TABLE)\n",
    "    print(f\"\\nstart.ipynb (Investor Process): post-process found row counts is {len(INVESTOR_TABLE.dataframe)} {datetime.now()}\")\n",
    "    \n",
    "    INVESTOR_TABLE.dataframe = INVESTOR_TABLE.dataframe.applymap(lambda x: str(x).replace(\".0\", \"\"))\n",
    "    INVESTOR_TABLE.dataframe['RID'] = INVESTOR_TABLE.dataframe['RID'].astype(str).apply(lambda x: x.zfill(13)).replace(['nan', '0000000000nan', '000000000None'], np.nan)\n",
    "    INVESTOR_TABLE.dataframe = INVESTOR_TABLE.dataframe.replace('nan', np.NaN)\n",
    "    INVESTOR_TABLE.dataframe.sort_values(\"RID\", inplace=True)\n",
    "    INVESTOR_TABLE.export()\n",
    "    \n",
    "    # check for missing records in INV_NF\n",
    "    INV_NF = pd.read_csv('./output/INV_NOT_FOUND.csv')\n",
    "    if len(INV_NF) > 0:\n",
    "        print('* Existing not found records, please fix the record and run cell 2.1.1')\n",
    "        \n",
    "except (KeyboardInterrupt):\n",
    "    pass\n",
    "\n",
    "except:\n",
    "    traceback_log()\n",
    "    print('Error occured')\n",
    "\n",
    "else:\n",
    "    finished(f'\\nstart.ipynb (Investor Process) {datetime.now()}')\n",
    "    INVESTOR_TABLE.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe61cd4",
   "metadata": {},
   "source": [
    "##### 2.1.2 Move from NOT FOUND back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade30766",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1.2 Re-add INV_NOT_FOUND data back to INV_TABLE (if fixed)\n",
    "# this part of the code will attempt to move fixed records to INVESTOR_TABLE\n",
    "\n",
    "# read NF files\n",
    "process = False\n",
    "try:\n",
    "    if len(INV_NF) >= 0:\n",
    "        process = True\n",
    "except (FileExistsError, FileNotFoundError):\n",
    "    print(f\"start.ipynb (Investor Update Process): length of NOT FOUND file is 0, no update is required {datetime.now()}\")\n",
    "except:\n",
    "    INV_NF = pd.read_excel('./output/INV_NOT_FOUND.xlsx')\n",
    "    process = True\n",
    "    \n",
    "# process\n",
    "if process:\n",
    "    try:\n",
    "        INV_NF.reset_index(drop=True, inplace=True)\n",
    "        to_drop_lst = []\n",
    "        if len(INV_NF) > 0:\n",
    "            for row in range(len(INV_NF)): # for all rows in NF\n",
    "                \n",
    "                # if sector and isic is empty, go to next row\n",
    "                if pd.isna(INV_NF.loc[row, 'SECTOR']) and pd.isna(INV_NF.loc[row, 'ISIC4_CLID']):\n",
    "                    pass\n",
    "                \n",
    "                # else format sector/isic and add row to investor table\n",
    "                else:\n",
    "                    INV_NF.loc[row, 'SECTOR'] = str(INV_NF.iloc[row]['SECTOR']).replace(\".0\", \"\")\n",
    "                    INV_NF.loc[row, 'ISIC4_CLID'] = str(INV_NF.iloc[row]['ISIC4_CLID']).replace(\".0\", \"\")\n",
    "                    INVESTOR_TABLE.dataframe = pd.concat([INVESTOR_TABLE.dataframe, INV_NF.iloc[[row]]], ignore_index=True)\n",
    "                    to_drop_lst.append(row)\n",
    "            print(f\"start.ipynb (Investor Update Process): INVESTOR TABLE updated, {len(to_drop_lst)} rows updated {datetime.now()}\")\n",
    "        \n",
    "        else:\n",
    "            print(f\"start.ipynb (Investor Update Process): length of NOT FOUND file is 0, no update is required {datetime.now()}\")           \n",
    "        \n",
    "        INV_NF = INV_NF.drop(index=to_drop_lst)\n",
    "        INV_NF.reset_index(drop=True, inplace=True)\n",
    "        INVESTOR_TABLE.dataframe.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "    except (KeyboardInterrupt):\n",
    "        pass\n",
    "\n",
    "    except: \n",
    "        print('Error occured')\n",
    "        traceback_log()\n",
    "        \n",
    "    else:\n",
    "        INVESTOR_TABLE.dataframe = INVESTOR_TABLE.dataframe.applymap(lambda x: str(x).replace(\".0\", \"\"))\n",
    "        INVESTOR_TABLE.dataframe['RID'] = INVESTOR_TABLE.dataframe['RID'].astype(str).apply(lambda x: x.zfill(13)).replace(['nan', '0000000000nan', '000000000None'], np.nan)\n",
    "        INVESTOR_TABLE.dataframe = INVESTOR_TABLE.dataframe.replace('nan', np.NaN)\n",
    "        INVESTOR_TABLE.dataframe.sort_values(\"RID\", inplace=True)\n",
    "        INVESTOR_TABLE.export()\n",
    "        \n",
    "        if len(INV_NF) > 0:\n",
    "            INV_NF.to_excel(\"./output/INV_NOT_FOUND.xlsx\", index=False)\n",
    "        else:\n",
    "            try:\n",
    "                os.remove('./output/INV_NOT_FOUND.xlsx')\n",
    "            except (FileNotFoundError):\n",
    "                pass\n",
    "            \n",
    "else:\n",
    "    try:\n",
    "        os.remove('./output/INV_NOT_FOUND.xlsx')\n",
    "    except (FileNotFoundError):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9086c545",
   "metadata": {},
   "source": [
    "### 2.2 Security Process (optional)\n",
    "- PIA data scraping\n",
    "- SR (DSR/ESR/FFR) data mapping\n",
    "- ISR data mapping\n",
    "##### *Please use personal internet connection for this part\n",
    "\n",
    "* Scraped around new 100 securities from over 1.6m rows, accounted for 0.00625% total rows required for processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac23a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Security Process (Optional)\n",
    "from system_modules.sys_security import *\n",
    "\n",
    "try:\n",
    "    print(f\"start.ipynb (Security Process): pre-process row counts is {len(SECURITY_TABLE.dataframe)}, {datetime.now()}\")\n",
    "    SECURITY_TABLE = security_validation(NEW_PIA_DF, SECURITY_TABLE, self_recheck_override=False)\n",
    "    print(f\"start.ipynb (Security Process): pre-process row counts is {len(SECURITY_TABLE.dataframe)}, {datetime.now()}\")\n",
    "    SECURITY_TABLE.dataframe[['BOP_item', 'issuer_countryID', 'scr_currencyID', 'scr_termID']] = SECURITY_TABLE.dataframe[['BOP_item', 'issuer_countryID', 'scr_currencyID', 'scr_termID']].applymap(lambda x: str(x).replace(\".0\", \"\"))\n",
    "    SECURITY_TABLE.dataframe = SECURITY_TABLE.dataframe.replace(['nan', '-'], np.NaN)# .replace('.0', np.NaN)\n",
    "    SECURITY_TABLE.dataframe\n",
    "    SECURITY_TABLE.export()\n",
    "\n",
    "\n",
    "except (KeyboardInterrupt):\n",
    "    pass\n",
    "\n",
    "except (Exception):\n",
    "    traceback_log()\n",
    "    print('Error occured')\n",
    "\n",
    "else:\n",
    "    finished(f'\\nstart.ipynb (Security Process) {datetime.now()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9e13c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SECURITY_TABLE.dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685ed43f",
   "metadata": {},
   "source": [
    "### 3. PIA Cleansing (monthly process)\n",
    "- SECURITY/INVESTOR TABLE mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIA cleansing method 1 (faster, no cache, utilize concurrent/multiprocessing, can't continue where left off)\n",
    "\n",
    "try:\n",
    "    print(f'start.ipynb: PIA cleansing running {datetime.now()}')\n",
    "    PIA_PROCESS_CACHE = cache(name='PIA_PROCESS_CACHE', data=[YEARLY_PIA_DF, NEW_PIA_DF, INVESTOR_TABLE, SECURITY_TABLE], force=True)\n",
    "    print(f'start.ipynb: PIA cleansing: cached, starting cleansing {datetime.now()}')\n",
    "    try:\n",
    "        output_terminal = subprocess.run([\"python\", \"./system_modules/sys_pia.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    except (FileNotFoundError):\n",
    "        output_terminal = subprocess.run([\"/storage-02/venv/local/nuntapoj/local_3a_env01/bin/python\", \"./system_modules/sys_pia.py\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(f'start.ipynb: PIA cleansing finished {datetime.now()}')\n",
    "    \n",
    "    # import files back\n",
    "    YEARLY_PIA_DF = PIA_PROCESS_CACHE.data[0]\n",
    "    NEW_PIA_DF =  PIA_PROCESS_CACHE.data[1]\n",
    "    INVESTOR_TABLE = PIA_PROCESS_CACHE.data[2]\n",
    "    SECURITY_TABLE = PIA_PROCESS_CACHE.data[3]\n",
    "    \n",
    "    # Loop to read the output line by line\n",
    "    for line in output_terminal.stdout.decode().splitlines():\n",
    "        print(line)\n",
    "\n",
    "    # Check if there were any errors\n",
    "    if output_terminal.returncode != 0:\n",
    "        print(\"Error:\", output_terminal.stderr.decode())\n",
    "    \n",
    "except (KeyboardInterrupt):\n",
    "    raise (KeyboardInterrupt)\n",
    "\n",
    "except (Exception):\n",
    "    traceback_log()\n",
    "    print('Error occured')\n",
    "    \n",
    "else:\n",
    "    # get all files in cache folder, then move current pia file from input to processed_input\n",
    "    cache_files = get_all_files(path='./cache', keyword='pia')\n",
    "    pia_to_move = [row.replace('.cache', '') if 'pia' in row else row for row in cache_files][0]\n",
    "    shutil.move(f\"./input/{pia_to_move}\", f\"./processed_input/{pia_to_move}\")\n",
    "    \n",
    "    # clear cache\n",
    "    clear_cache()\n",
    "    \n",
    "    finished(f'\\nstart.ipynb (PIA Process) {datetime.now()}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608076b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "YEARLY_PIA_DF.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ea9920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEW_PIA_DF_SHORTEN = NEW_PIA_DF\n",
    "# NEW_PIA_DF_SHORTEN.dataframe = NEW_PIA_DF.dataframe.sample(5000)\n",
    "# IA_PROCESS_CACHE = cache(name='PIA_PROCESS_CACHE', data=[YEARLY_FLOW_DF, YEARLY_PIA_DF, NEW_PIA_DF, INVESTOR_TABLE, SECURITY_TABLE], force=True)\n",
    "# %run -i ./system_modules/sys_pia.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcc9a85",
   "metadata": {},
   "source": [
    "# Test\n",
    "Use case: If program cached current process records and got struck, use clear cache can reset current processed records\n",
    "\n",
    "Note:\n",
    "- Cache for PIA will cache the current processed row for PIA file in 3.\n",
    "- Cache for INVESTOR/SECURITY will cache the current processed row for PIA file in 2., and also the file that it is processing (meaning there can be many cache files for SEC/INV, each saved separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398f1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
